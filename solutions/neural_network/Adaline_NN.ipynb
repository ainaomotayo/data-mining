{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabh/Documents/pseudoDesktop/personalStuff/programming/data_science/dmct/pynb/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "i_data = iris[\"data\"][:,:2]\n",
    "target = iris[\"target\"]\n",
    "\n",
    "# dicretisize target labels ,  target class : 0\n",
    "target = [0 if t == 0 else 1 for t in target]\n",
    "        \n",
    "data = MinMaxScaler().fit_transform(i_data)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, target, test_size = 0.25, random_state=33)\n",
    "N, M = train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Adaline Neural Net </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineNN(object):\n",
    "    def __init__(self,epochs,learning_rate):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_function = lambda x : 1.0/(1.0 + np.exp(-x))\n",
    "        \n",
    "    def init_weights(self,data):\n",
    "        self.n_attributes = data.shape[1]\n",
    "        self.weights = np.array(random.sample(range(0, 100), self.n_attributes + 1))/100\n",
    "        self.weights = self.weights.reshape((1, self.n_attributes + 1))\n",
    "        self.weights[0][-1] = 1\n",
    "        print(self.weights)\n",
    "        \n",
    "    def predict_class(self, row):\n",
    "        h = 0\n",
    "        for j in range(0, len(row)):\n",
    "            h += row[j]*self.weights[0][j]\n",
    "        h += 1\n",
    "        g = self.activation_function(h)\n",
    "        return g\n",
    "    \n",
    "    def update_weights(self, t, g, row):\n",
    "        err = t - g\n",
    "        for i in range(0, len(row)):\n",
    "            error_term = self.learning_rate*err*row[i]\n",
    "            self.weights[0][i] += error_term\n",
    "        \n",
    "    def train(self, data, targets):\n",
    "        self.init_weights(data)\n",
    "        iters = 0\n",
    "        while(iters < self.epochs):\n",
    "            iters += 1\n",
    "            for i in range(0, len(data)):\n",
    "                g = self.predict_class(data[i])\n",
    "                self.update_weights(targets[i], g, data[i])\n",
    "        print(self.weights)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return [round(self.predict_class(row)) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adnn = AdalineNN(epochs=20,learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cb5a8071bead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_Y' is not defined"
     ]
    }
   ],
   "source": [
    "adnn.train(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adnn.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predictions, test_y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
